---
title: "Logistic_Regression"
author: "Walid Keddad"
output: pdf_document
---
##Exercice 1 : Modèle Logistique Simple

On a relevé l'âge et la présence(1) ou l'absence (0) d'une maladie cardiovasculaire chez 100 individus.
Les données sont stockées dans le fichier "MCV.txt": sur une ligne donnée, la variable AGE fournit
l'âge d'un individu tandis que la variable CHD prend la valeur 1 en cas de présence d'une maladie
cardiovasculaire chez cet individu et la valeur 0 sinon. Les variables ID et AGRP donnent
respectivement le numéro d'un individu et sa classe d'âge.


**chargement des données: **
```{r}
setwd("f:/ml")
data = read.csv("MCV.txt" , header = T , sep = "\t")
head(data)
summary(data)
```

On veut étudier la relation entre **CHD** et la variable explicative **AGE** , on les représente avec un nuage de point :

```{r}
plot(data$AGE,data$CHD,xlab = "AGE" ,ylab = "Présence de maladie" , main = "CHD ~ AGE")
```

On constate que l'age a un impact sur la présence de maladie , plus une personne est agé plus elle est la probabilté qu'elle soit malade

**.**

On calcule la proportion de malades observée selon les classes d'âge définies par la variable **AGRP** , et On crée un vecteur qui donne les centres de chaque classe 

```{r}
proportion = tapply(data$CHD,data$AGRP, mean)
proportion
centres = tapply(data$AGE,data$AGRP, median)
centres
```

Nuage de points de **proportion** en fonction de **centres**
```{r}
plot(proportion~centres , pch = 19 , col = "purple")
```

On voit qu'il y a une relation entre **AGE** et **CHD** , et on voit aussi que le graphe a une curve **sigmoid** donc on peut appliquer un regression logistique sur ces données


**.**

Commençons par ajuster une régression logistique de **CHD** en fonction de **AGE** :

```{r}
mpg_model = glm(data$CHD~data$AGE ,"binomial")
summary(mpg_model)
```

Comme la valeur p de **AGE** est égale a **2.82e-06** donc la variable AGE est significative dans le model .
Nombre de degrés de liberté **98**


**.**

Afin de mieux discerner les relations entre les différentes classes, on va représenter sur un même graphique les proportions selon la **classe d'âge** et la **courbe logistique ajustée**.

```{r}
coefs = coef(mpg_model)
intercept = coefs[1]
age_coef = coefs[2]  
point = seq(0,100,length=100)
plot(centres,proportion,col="purple",pch=19)
lines(point,plogis(intercept + age_coef*point),col='pink',lwd=2 ,lty=5 )
```


Maintenant on va ajuster le model **probit** : 

```{r}
probit_model = glm(data$CHD~data$AGE , "binomial"(link="probit"))
summary(probit_model)
intercept2 = probit_model$coefficients[1]
age_coef2 = probit_model$coefficients[2]
plot(centres,proportion,col="purple",pch=19)
lines(point,pnorm(intercept2 + age_coef2*point),col='green',lwd=2 , lty=4 )

```

On voit que les deux models **probit** et **logit** sont pas très différents, ils donnent le meme resultat





##Exercice 2 : Modèle Logistique Multiple

Nous traitons un problème de défaut bancaire. Nous cherchons à déterminer quels clients seront en
défaut sur leur dette de carte de crédit (ici defaut = 1 si le client fait défaut sur sa dette). La variable
defaut est la variable réponse. La base de données Defaut est accessible à partir du package ISLR que
vous devez installer au préalable.
La base Defaut dispose d'un échantillon de tailles 10000 et 3 variables explicatives. Les variables
explicatives sont les suivantes :
. student: variable à 2 niveaux {0,1} (student = 1 si le client est un étudiant).
. balance: montant moyen mensuel d'utilisation de la carte de crédit.
. income: revenu du client.


**Chargement des données :**

```{r}
library(ISLR)
def = Default
attach(def)
head(def)
summary(def)
```

Afin de faciliter le traitement, on transforme la variable default à 0 si Non et 1 si Yes

```{r}
def$default = ifelse( def$default == "No" ,0,1)
head(def)
```

On Construit un modèle de régression logistique avec la variable **balance** comme variable
explicative qualitative

```{r}
balance_model = glm(default~balance , family = "binomial"(link = "logit"))
summary(balance_model)
```


Une fois que les coefficients ont été estimés, il est simple de calculer la probabilité de défaut
étant donné balance (solde moyen de carte de crédit donné). En utilisant les estimations des
coefficients indiqués dans le tableau précédant, on va prédire la probabilité de defaut pour un client qui a une balance de **1000**, **1500**, **2000** et **3000** dollars respectivement. 

```{r}
test = data.frame(balance=c(1000,1500,2000,3000))
result = predict.glm(balance_model , test , type = "response")
result

```

On voit que la probabilité de **défault** augmente avec l'augmentation du **balance**



Tableau de contingence des variables **default** et **student** :

```{r}
table(student , default)
```

Model Logit avec **student** comme variable explicative :

```{r}
student_model = glm(default~student , "binomial"(link = "logit"))
summary(student_model)

student_model$coefficients[1] # -3.5041
student_model$coefficients[2] # 0.4048

# p(default = yes , student = yes ) = e(-3.50 + 0.40 * 1) / 1 + (e(-3.50 + 0.40 * 1))

# p(default = yes , student = no ) = e(-3.50 + 0.40 * 0) / 1 + (e(-3.50 + 0.40 * 0))


```

Maintenant on construit un modèle de régression logistique multiple avec les 2 variables explicatives
**student** et **balance**.

```{r}
student_balance_model = glm(default~student + balance , family = "binomial")
summary(student_balance_model)
```

Un modèle de régression logistique multiple avec les 3 variables explicatives
**student** et **balance** et **income**.

```{r}
student_balance_income_model = glm(default~student + balance + income , family = "binomial")
summary(student_balance_income_model)
```





##Exercice 3 : Modèle linéaire généralisé


Supposons que nous partons d'une partie du jeu de données " mtcars" intégré dans R. Les données
ont été extraites du magazine 1974 de Motor Trend US et comprennent la consommation de carburant
et 10 aspects de la conception et de la performance automobile pour 32 automobiles (modèles 1973-
74). Nous utiliserons "vs" comme variable de résultat, "mpg" comme prédicteur continu, et "am"
comme prédicteur catégorique (dichotomique ou binaire).


**Chargement des données :** 

```{r}
data("mtcars")
head(mtcars)
summary(mtcars)
attach(mtcars)

```

On va créer un modèle logistique où on considére **mpg** est la variable prédictive continue et **vs** est la variable de résultat qualitative binaire.

```{r}
mpg_model = glm(vs~mpg , "binomial")
summary(mpg_model)
```

Traçant avec la fonction plot le graphe des données et du modèle régression logistique


```{r}
plot(mpg , vs , col=6 , pch = 19)
intercept = mpg_model$coefficients[1]
coef_mpg = mpg_model$coefficients[2]
point = seq(0,100,length.out = 100)
lines(point,plogis(intercept + coef_mpg*point),col='purple',lwd=2 ,lty=5 )

```

On va refaire la même chose avec la variable **am** comme variable prédective 

```{r}
am_model = glm(vs ~ am , family = "binomial"(link = logit))
summary(am_model)
plot(am , vs )
am_intercept = am_model$coefficients[1]
coef_am = am_model$coefficients[2]
lines(point,plogis(am_intercept + coef_am * point) , col ="blue" , lwd = 2 , lty = 5)
```

Construisant maintenant le modèle de régression avec **mpg** comme variable prédictive continue, **am** comme variable prédictive dichotomique et **vs** comme variable de résultat qualitative
binaire (dichotomique).

```{r}
multi_model = glm(vs ~ am + mpg , family = "binomial"(link = logit))
summary(multi_model)
plot (am + mpg , vs , col = "red" , pch = 19)
multi_intercept = multi_model$coefficients[1]
am_coef = multi_model$coefficients[2]
mpg_coef = multi_model$coefficients[3]
lines(point , plogis(multi_intercept + (am_coef * point) + (mpg_coef * point)) , col = "blue" , lty = 5 )

```

Comparant les résultats avec le model probit :


```{r}
probit_model = glm(vs ~ mpg + am , data = mtcars , family = "binomial"(link = "probit"))
summary(probit_model)
plot(mpg + am , vs , col=4 , pch = 19)
intercept = probit_model$coefficients[1]
coef_mpg = probit_model$coefficients[2]
coef_am = probit_model$coefficients[3]
point = seq(0,100,length.out = 100)
lines(point,plogis(intercept + coef_mpg*point + coef_am*point),col='red',lwd=2 ,lty=5 )

```

On contate que les résultats sont similaires **logit** et **probit**





